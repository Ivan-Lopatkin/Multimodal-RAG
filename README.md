# Multimodal-RAG

---

## Структура репозитория

- `app.py`  
  Основной файл приложения для запуска сервиса.

- `requirements.txt`  
  Список зависимостей, необходимых для работы проекта.

- `data/`  
  Директория с данными для индексирования и поиска.
  
- `src/`  
  Исходный код проекта.
  - `llm/`  
    Модули для работы с большими языковыми моделями.
  - `retrievers/`  
    Модули для извлечения релевантной информации.
  - `utils.py`  
    Вспомогательные функции и утилиты.

---

## Запуск

Для запуска проекта необходимо выполнить следующие шаги:


1. **Создайте и активируйте виртуальное окружение:**

    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

2. **Установите зависимости:**

    ```bash
    pip install -r requirements.txt
    ```

3. **Запустите приложение:**

    ```bash
    streamlit run app.py
    ```

4. **Доступ к приложению:**

    Откройте веб-браузер и перейдите по адресу `http://localhost:8000`.

---

## Время сборки и запуска

1. **Установка зависимостей:**  
   - Занимает около **2 минут**.

2. **Запуск приложения:**  
   - Мгновенный запуск после установки зависимостей.
---

## Обзор Решения

Наш проект включает следующие ключевые компоненты:

**Индексирование данных**
- Использование **FAISS** для эффективного поиска по эмбеддингам.
- Хранение метаданных и эмбеддингов для быстрого доступа.

**Работа с LLM**
- Интеграция с Pixtral-12b для генерации ответов.


## Гипотеза: Совмещение текстовых и визуальных эмбеддингов для улучшения мультимодального поиска

Основной гипотезой нашего решения является предположение, что комбинирование эмбеддингов текстовой и визуальной модальностей позволяет значительно улучшить точность и качество мультимодального поиска. Мы считаем, что интеграция данных из разных типов источников (текстовых описаний и изображений) обеспечивает более глубокое понимание контекста и повышает релевантность выдачи.

---

### Наш подход: стратегии реализации гипотезы

Для проверки этой гипотезы мы разработали несколько стратегий, которые позволяют по-разному комбинировать текстовые и визуальные эмбеддинги. Каждая из них представляет собой часть общего подхода к решению задачи мультимодального поиска.

#### 1. **SummaryEmb**
Эта стратегия извлекает изображения, используя текстовые эмбеддинги, полученные из описаний (summary) изображений при помощи Pixtral-12b. Она помогает учитывать текстовый контекст изображений, но не задействует визуальную информацию напрямую.

#### 2. **ColQwen**
Визуальные эмбеддинги, полученные через модель ViT, используются для извлечения изображений, релевантных запросу. Стратегия позволяет учитывать исключительно визуальные характеристики изображений.

#### 3. **Intersection**
В этой стратегии комбинируются результаты двух модальностей через пересечение изображений, найденных текстовыми и визуальными эмбеддингами. Это позволяет учитывать и текстовую, и визуальную релевантность, что важно для мультимодальных запросов.

#### 4. **ColQwen+SummaryEmb**
Эта стратегия объединяет топовые результаты текстовых и визуальных эмбеддингов, выбирая наиболее релевантные изображения из обоих подходов. Она помогает эффективно решать задачи, где требуется мультимодальный анализ.

